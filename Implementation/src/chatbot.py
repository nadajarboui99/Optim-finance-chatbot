import os
import sys
# R√©soudre le probl√®me des tokenizers Hugging Face
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from typing import Dict, Any, List, Optional
from search import SearchEngine
from llm_integration import LLMIntegration
from config import Config
import traceback

class OptimFinanceChatbot:
    def __init__(self, silent_mode: bool = False, use_chromadb=True):
        self.search_engine = SearchEngine(use_chromadb=use_chromadb)
        self.llm = LLMIntegration()
        self.is_initialized = False
        self.silent_mode = silent_mode
    
    def _print(self, message: str):
        """Print conditionnel selon le mode silencieux"""
        if not self.silent_mode:
            print(message)
    
    def initialize(self) -> None:
        """Initialiser le chatbot"""
        self._print("Initialisation du chatbot OPTIM Finance...")
        try:
            # Initialiser le moteur de recherche
            self.search_engine.initialize()
            
            # Tester la connexion LLM
            if self.llm.test_connection():
                self.is_initialized = True
                self._print("‚úÖ Chatbot initialis√© avec succ√®s!")
            else:
                self._print("‚ùå Erreur: Impossible de se connecter au LLM")
                raise Exception("√âchec de l'initialisation du LLM")
                
        except Exception as e:
            self._print(f"‚ùå Erreur lors de l'initialisation: {e}")
            raise
    
    def process_query(self, user_query: str, search_type: str = "hybrid", top_k: Optional[int] = None) -> Dict[str, Any]:
        """Traiter une requ√™te utilisateur compl√®te"""
        if not self.is_initialized:
            return {
                'query': user_query,
                'response': 'Chatbot non initialis√©. Appelez initialize() d\'abord.',
                'error': 'not_initialized',
                'confidence': 'error'
            }
        
        try:
            self._print(f"\n{'='*50}")
            self._print(f"üîç TRAITEMENT DE LA REQU√äTE: '{user_query}'")
            self._print(f"{'='*50}")
            
            # 1. Recherche dans la base de connaissances
            self._print("üìö √âtape 1: Recherche dans la base de connaissances...")
            search_results = self.search_engine.search(
                query=user_query,
                search_type=search_type,
                top_k=top_k
            )
            
            self._print(f"üìä R√©sultats de recherche:")
            self._print(f"  - Nombre de r√©sultats: {len(search_results['results'])}")
            self._print(f"  - Intention d√©tect√©e: {search_results['intent']}")
            
            # 2. V√©rifier si on a des r√©sultats pertinents
            if not search_results['results']:
                self._print("‚ö†Ô∏è Aucun r√©sultat pertinent trouv√©")
                return {
                    'query': user_query,
                    'response': f"Je n'ai pas trouv√© d'informations sp√©cifiques sur votre question. Pour une r√©ponse personnalis√©e, contactez notre √©quipe √† {Config.CONTACT_EMAIL} ou au {Config.CONTACT_PHONE}.",
                    'intent': search_results['intent'],
                    'sources': [],
                    'confidence': 'low',
                    'num_sources': 0,
                    'search_type': search_type
                }
            
            # Debug: afficher les premiers r√©sultats
            if not self.silent_mode:
                self._print(f"üîç Aper√ßu des r√©sultats:")
                for i, result in enumerate(search_results['results'][:2]):
                    score = result.get('final_score', result.get('similarity_score', result.get('keyword_score', 0)))
                    self._print(f"  R√©sultat {i+1} - Score: {score:.3f}")
                    self._print(f"  Titre: {result.get('title', 'N/A')}")
                    self._print(f"  Contenu (preview): {str(result.get('content', ''))[:100]}...")
            
            # 3. G√©n√©ration de la r√©ponse avec LLM
            self._print("ü§ñ √âtape 2: G√©n√©ration de la r√©ponse avec LLM...")
            llm_response = self.llm.generate_response(
                user_query=user_query,
                retrieved_chunks=search_results['results'],
                intent=search_results['intent']
            )
            
            # V√©rifier si la g√©n√©ration LLM a r√©ussi
            if not llm_response.get('success', True):
                self._print(f"‚ùå Erreur LLM: {llm_response.get('error', 'Erreur inconnue')}")
                return {
                    'query': user_query,
                    'response': llm_response['response'],  # Message d'erreur d√©j√† format√©
                    'intent': search_results['intent'],
                    'sources': [],
                    'confidence': 'error',
                    'num_sources': len(search_results['results']),
                    'search_type': search_type,
                    'error': llm_response.get('error')
                }
            
            # 4. √âvaluer la confiance bas√©e sur les scores
            confidence = self._evaluate_confidence(search_results['results'])
            
            self._print("‚úÖ R√©ponse g√©n√©r√©e avec succ√®s!")
            if not self.silent_mode:
                self._print(f"üìà Statistiques finales:")
                self._print(f"  - Confiance: {confidence}")
                self._print(f"  - Sources utilis√©es: {len(search_results['results'])}")
                self._print(f"  - Longueur de la r√©ponse: {len(llm_response['response'])} caract√®res")
            
            return {
                'query': user_query,
                'response': llm_response['response'],
                'intent': search_results['intent'],
                'sources': llm_response['sources'],
                'confidence': confidence,
                'num_sources': len(search_results['results']),
                'search_type': search_type,
                'success': True
            }
            
        except Exception as e:
            error_msg = f"Erreur lors du traitement: {str(e)}"
            self._print(f"‚ùå {error_msg}")
            self._print(f"üîß Type d'erreur: {type(e).__name__}")
            if not self.silent_mode:
                self._print(f"üìã Stack trace:")
                traceback.print_exc()
            
            return {
                'query': user_query,
                'response': f"D√©sol√©, une erreur est survenue. Veuillez contacter notre √©quipe √† {Config.CONTACT_EMAIL}",
                'error': error_msg,
                'confidence': 'error',
                'intent': 'unknown',
                'sources': [],
                'num_sources': 0,
                'success': False
            }
    
    def _evaluate_confidence(self, results: List[Dict[str, Any]]) -> str:
        """√âvaluer la confiance de la r√©ponse bas√©e sur les scores"""
        if not results:
            return 'low'
        
        try:
            # Prendre le meilleur score
            scores = []
            for r in results:
                score = r.get('final_score', r.get('similarity_score', r.get('keyword_score', 0)))
                if isinstance(score, (int, float)):
                    scores.append(score)
            
            if not scores:
                return 'low'
            
            best_score = max(scores)
            
            if best_score > 0.8:
                return 'high'
            elif best_score > 0.6:
                return 'medium'
            else:
                return 'low'
                
        except Exception as e:
            self._print(f"‚ö†Ô∏è Erreur lors de l'√©valuation de confiance: {e}")
            return 'low'
    
    def get_suggestions(self, partial_query: str) -> List[str]:
        """Obtenir des suggestions bas√©es sur une requ√™te partielle"""
        suggestions = [
            "Quels sont les tarifs du portage salarial ?",
            "Quelle diff√©rence entre auto-entreprise et soci√©t√© ?",
            "Comment vous contacter ?",
            "Quels sont les avantages du portage salarial ?",
            "Combien co√ªte la cr√©ation d'une soci√©t√© ?",
            "Qu'est-ce que le portage salarial ?",
            "Quels sont les frais de gestion ?",
            "Comment fonctionne la facturation ?",
            "Quelles sont vos zones d'intervention ?",
            "Comment d√©marrer avec OPTIM Finance ?"
        ]
        
        if partial_query and len(partial_query.strip()) > 2:
            # Filtrer les suggestions bas√©es sur la requ√™te partielle
            partial_lower = partial_query.lower().strip()
            filtered = [s for s in suggestions if partial_lower in s.lower()]
            return filtered[:3] if filtered else suggestions[:3]
        
        return suggestions[:3]
    
    def get_status(self) -> Dict[str, Any]:
        """Obtenir le statut du chatbot"""
        return {
            'initialized': self.is_initialized,
            'search_engine_ready': hasattr(self.search_engine, 'vectorstore') if hasattr(self, 'search_engine') else False,
            'llm_ready': self.llm.test_connection() if hasattr(self, 'llm') else False
        }

# Interface CLI pour tester
def main():
    try:
        print("üöÄ D√©marrage du chatbot OPTIM Finance...")
        chatbot = OptimFinanceChatbot(silent_mode=False)  # Mode verbose pour CLI
        
        print("‚ö° Initialisation en cours...")
        chatbot.initialize()
        
        print(f"\n{'='*60}")
        print("ü§ñ Assistant OPTIM Finance - PR√äT")
        print("üí° Tapez 'quit', 'exit' ou 'q' pour quitter")
        print("üìä Tapez 'status' pour voir l'√©tat du syst√®me")
        print("‚ùì Tapez 'help' pour voir les suggestions")
        print(f"{'='*60}")
        
        while True:
            try:
                user_input = input("\nü§î Votre question: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("üëã Au revoir !")
                    break
                
                if user_input.lower() == 'status':
                    status = chatbot.get_status()
                    print(f"\nüìä Statut du syst√®me:")
                    for key, value in status.items():
                        emoji = "‚úÖ" if value else "‚ùå"
                        print(f"  {emoji} {key}: {value}")
                    continue
                
                if user_input.lower() == 'help':
                    suggestions = chatbot.get_suggestions("")
                    print(f"\nüí° Suggestions de questions:")
                    for i, suggestion in enumerate(suggestions, 1):
                        print(f"  {i}. {suggestion}")
                    continue
                
                if not user_input:
                    print("‚ö†Ô∏è Veuillez poser une question.")
                    continue
                
                # Traitement de la requ√™te
                response = chatbot.process_query(user_input)
                
                # Affichage de la r√©ponse
                print(f"\nüí¨ R√©ponse: {response['response']}")
                print(f"üéØ Intention d√©tect√©e: {response['intent']}")
                print(f"üìä Confiance: {response['confidence']}")
                print(f"üìö Sources utilis√©es: {response.get('num_sources', 0)}")
                
                if response.get('error'):
                    print(f"‚ö†Ô∏è Erreur technique: {response['error']}")
                
            except KeyboardInterrupt:
                print("\n‚õî Arr√™t demand√© par l'utilisateur.")
                break
            except Exception as e:
                print(f"\n‚ùå Erreur inattendue: {e}")
                traceback.print_exc()
                
    except Exception as e:
        print(f"üí• Erreur critique lors du d√©marrage: {e}")
        traceback.print_exc()

class NullWriter:
    """Classe pour rediriger stdout/stderr vers nulle part"""
    def write(self, x): pass
    def flush(self): pass

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # Mode backend: une seule question en argument - MODE SILENCIEUX TOTAL
        question = sys.argv[1]

        # Sauvegarder les r√©f√©rences originales
        original_stdout = sys.stdout
        original_stderr = sys.stderr
        
        try:
            # Rediriger TOUTES les sorties vers null pendant l'initialisation et le traitement
            sys.stdout = NullWriter()
            sys.stderr = NullWriter()
            
            # Cr√©er le chatbot en mode silencieux
            chatbot = OptimFinanceChatbot(silent_mode=True)
            chatbot.initialize()

            response = chatbot.process_query(question)
            
            # Restaurer stdout pour afficher SEULEMENT la r√©ponse
            sys.stdout = original_stdout
            sys.stderr = original_stderr
            
            # Afficher SEULEMENT la r√©ponse pour Node.js
            print(response["response"])
            
        except Exception as e:
            # Restaurer les sorties en cas d'erreur
            sys.stdout = original_stdout
            sys.stderr = original_stderr
            
            # En cas d'erreur, afficher un message d'erreur simple
            print(f"D√©sol√©, une erreur est survenue. Veuillez contacter notre √©quipe √† contact@optim-finance.com")
    else:
        # Mode CLI interactif - MODE VERBOSE
        main()